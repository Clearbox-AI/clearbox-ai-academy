{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzwHb4DJch7r"
   },
   "source": [
    "### Create a dataset to finetune a Language Model for Medical Q&A ü©∫üí°\n",
    "\n",
    "Welcome to this exciting journey where we fine-tune a Language Model (LLM) to respond effectively and safely to medical questions! üöÄ The goal is to create an AI assistant that can assist users in understanding medical concepts, answering health-related inquiries, and supporting healthcare professionals in a supplementary role. üåü\n",
    "\n",
    "In this notebook, we‚Äôll leverage the ChatDoctor Dataset üóÇÔ∏è, sourced from the Hugging Face repository: [ChatDoctor Dataset](https://huggingface.co/datasets/avaliev/chat_doctor).\n",
    "\n",
    "This dataset is a curated collection of medical dialogues designed to train models in the nuanced task of medical communication.\n",
    "\n",
    "Follow the instructions in this notebook to complete the practice task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vdRlw_zrcYbg"
   },
   "outputs": [],
   "source": [
    "# importing the needed modules\n",
    "\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inG10_a8fZPX"
   },
   "source": [
    "Loading Q&A Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_w16TID6fWhY",
    "outputId": "7aae825d-0e28-483e-826f-eacef240cf7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95588/95588 [00:01<00:00, 60002.49 examples/s]\n",
      "Generating validation split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11949/11949 [00:00<00:00, 43925.05 examples/s]\n",
      "Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11949/11949 [00:00<00:00, 57793.53 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"avaliev/chat_doctor\", split = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'instruction', 'output'],\n",
       "    num_rows: 11949\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lonv3bPkfvc7"
   },
   "source": [
    "write a python method called `convert_to_training_dataset`that gets a dataframe and convert each record to a dictionary (json object) with the proper format.\n",
    "\n",
    "`hint: Do not forget to add the system_prompt!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3ag28by_frs8"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UileM-5gOY0"
   },
   "source": [
    "use the `convert_to_training_dataset` method and store the json objects in a json file called `training_data.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rAgmV2YWgfa1"
   },
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
